<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AWS Glue: Data Integration Service</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Arial', sans-serif;
            line-height: 1.6;
            color: #333;
            background: #ffffff;
        }

        .slide {
            width: 100%;
            min-height: 100vh;
            padding: 60px 80px 80px 80px;
            page-break-after: always;
            display: flex;
            flex-direction: column;
            justify-content: center;
            position: relative;
        }
        
        .slide-footer {
            position: absolute;
            bottom: 20px;
            right: 80px;
            font-size: 0.9rem;
            color: #6b7280;
            font-style: italic;
            text-align: center;
        }

        .slide:last-child {
            page-break-after: auto;
        }

        .slide-header {
            text-align: center;
            margin-bottom: 50px;
        }

        .title-slide {
            background: linear-gradient(135deg, #232F3E 0%, #FF9900 100%);
            color: white;
            text-align: center;
        }

        .slide-title {
            font-size: 3.5rem;
            font-weight: bold;
            margin-bottom: 30px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .slide-subtitle {
            font-size: 1.8rem;
            font-weight: 300;
            margin-bottom: 40px;
            opacity: 0.9;
        }

        h1 {
            font-size: 2.8rem;
            color: #232F3E;
            margin-bottom: 30px;
            text-align: center;
            border-bottom: 3px solid #FF9900;
            padding-bottom: 15px;
        }

        h2 {
            font-size: 2.2rem;
            color: #232F3E;
            margin-bottom: 25px;
            border-bottom: 2px solid #FF9900;
            padding-bottom: 10px;
        }

        h3 {
            font-size: 1.6rem;
            color: #232F3E;
            margin-bottom: 20px;
            margin-top: 30px;
        }

        h4 {
            font-size: 1.3rem;
            color: #FF9900;
            margin-bottom: 15px;
        }

        p {
            font-size: 1.1rem;
            margin-bottom: 20px;
            text-align: justify;
        }

        ul, ol {
            margin-left: 30px;
            margin-bottom: 20px;
        }

        li {
            font-size: 1.1rem;
            margin-bottom: 10px;
            line-height: 1.6;
        }

        .highlight-box {
            background: #f3f4f6;
            border-left: 5px solid #FF9900;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        .comparison-table th,
        .comparison-table td {
            padding: 15px;
            text-align: left;
            border-bottom: 1px solid #e5e7eb;
        }

        .comparison-table th {
            background: #232F3E;
            color: white;
            font-weight: 600;
        }

        .comparison-table tr:hover {
            background: #f3f4f6;
        }

        .grid-container {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .grid-item {
            background: #f8fafc;
            padding: 20px;
            border-radius: 8px;
            border: 1px solid #e2e8f0;
        }

        .grid-item h4 {
            color: #232F3E;
            margin-bottom: 10px;
            font-size: 1.2rem;
        }

        .code-block {
            background: #1e293b;
            color: #e2e8f0;
            padding: 20px;
            border-radius: 8px;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            overflow-x: auto;
            margin: 20px 0;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .warning-box {
            background: #fef2f2;
            border-left: 5px solid #ef4444;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .success-box {
            background: #f0fdf4;
            border-left: 5px solid #22c55e;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .architecture-diagram {
            background: #f8fafc;
            border: 2px solid #e2e8f0;
            border-radius: 10px;
            padding: 30px;
            margin: 20px 0;
            text-align: center;
        }

        .flow-step {
            display: inline-block;
            background: #232F3E;
            color: white;
            padding: 10px 20px;
            margin: 5px;
            border-radius: 20px;
            font-weight: bold;
        }

        .arrow {
            font-size: 1.5rem;
            color: #FF9900;
            margin: 0 10px;
        }

        @media print {
            .slide {
                page-break-inside: avoid;
            }
        }
    </style>
</head>
<body>

    <!-- Title Slide -->
    <div class="slide title-slide">
        <div class="slide-header">
            <h1 class="slide-title">AWS Glue</h1>
            <p class="slide-subtitle">Serverless Data Integration Service</p>
            <p style="font-size: 1.2rem; margin-top: 40px;">Extract, Transform, Load (ETL) and Data Catalog</p>
        </div>
        <div class="slide-footer">AWS Training Series</div>
    </div>

    <!-- What is AWS Glue -->
    <div class="slide">
        <h1>What is AWS Glue?</h1>
        
        <div class="highlight-box">
            <p><strong>AWS Glue is a fully managed extract, transform, and load (ETL) service that makes it easy to prepare and load your data for analytics.</strong></p>
        </div>

        <h3>Key Characteristics:</h3>
        <ul>
            <li><strong>Serverless:</strong> No infrastructure to manage or provision</li>
            <li><strong>Fully Managed:</strong> AWS handles scaling, patching, and maintenance</li>
            <li><strong>Pay-per-use:</strong> Only pay for resources consumed during job runs</li>
            <li><strong>Apache Spark-based:</strong> Built on Apache Spark for distributed processing</li>
            <li><strong>Code Generation:</strong> Automatically generates ETL code in Python or Scala</li>
        </ul>

        <h3>Main Components:</h3>
        <div class="grid-container">
            <div class="grid-item">
                <h4>Data Catalog</h4>
                <p>Central metadata repository for all your data assets</p>
            </div>
            <div class="grid-item">
                <h4>ETL Engine</h4>
                <p>Serverless Apache Spark environment for data transformation</p>
            </div>
            <div class="grid-item">
                <h4>Crawlers</h4>
                <p>Automatically discover and catalog data schemas</p>
            </div>
            <div class="grid-item">
                <h4>Job Scheduler</h4>
                <p>Trigger jobs based on schedules or events</p>
            </div>
        </div>

        <div class="slide-footer">AWS Glue Overview</div>
    </div>

    <!-- Why Do We Need AWS Glue -->
    <div class="slide">
        <h1>Why Do We Need AWS Glue?</h1>
        
        <h2>Traditional ETL Challenges:</h2>
        <ul>
            <li><strong>Infrastructure Management:</strong> Setting up and maintaining ETL servers</li>
            <li><strong>Scaling Issues:</strong> Manual scaling for varying workloads</li>
            <li><strong>Schema Discovery:</strong> Manually cataloging data sources and schemas</li>
            <li><strong>Code Complexity:</strong> Writing complex ETL code from scratch</li>
            <li><strong>Data Silos:</strong> Difficulty in discovering and accessing distributed data</li>
            <li><strong>Cost Inefficiency:</strong> Paying for idle infrastructure</li>
        </ul>

        <h2>AWS Glue Solutions:</h2>
        <div class="grid-container">
            <div class="grid-item">
                <h4>üöÄ Serverless</h4>
                <p>No infrastructure to manage, automatic scaling</p>
            </div>
            <div class="grid-item">
                <h4>üìä Auto Discovery</h4>
                <p>Crawlers automatically discover and catalog data</p>
            </div>
            <div class="grid-item">
                <h4>üîß Code Generation</h4>
                <p>Automatically generates ETL code with visual editor</p>
            </div>
            <div class="grid-item">
                <h4>üí∞ Cost Effective</h4>
                <p>Pay only for what you use, no idle costs</p>
            </div>
        </div>

        <div class="slide-footer">Why AWS Glue?</div>
    </div>

    <!-- Use Cases -->
    <div class="slide">
        <h1>AWS Glue Use Cases</h1>
        
        <h2>1. Data Lake Analytics</h2>
        <div class="highlight-box">
            <p>Build and maintain data lakes by cataloging, cleaning, and transforming data from various sources into analytics-ready formats.</p>
        </div>

        <h2>2. Data Warehouse Modernization</h2>
        <ul>
            <li>Migrate from traditional on-premises data warehouses</li>
            <li>Transform and load data into Amazon Redshift or other cloud data warehouses</li>
            <li>Implement incremental data loading strategies</li>
        </ul>

        <h2>3. Real-time Analytics</h2>
        <ul>
            <li>Process streaming data from Kinesis Data Streams</li>
            <li>Transform and enrich real-time data</li>
            <li>Load processed data into analytics services</li>
        </ul>

        <h2>4. Machine Learning Data Preparation</h2>
        <ul>
            <li>Clean and prepare data for ML model training</li>
            <li>Feature engineering and data transformation</li>
            <li>Integration with Amazon SageMaker</li>
        </ul>

        <h2>5. Data Integration & Migration</h2>
        <ul>
            <li>Integrate data from multiple sources (databases, files, APIs)</li>
            <li>Migrate data between different storage systems</li>
            <li>Standardize data formats across the organization</li>
        </ul>

        <div class="slide-footer">AWS Glue Use Cases</div>
    </div>

    <!-- Data Catalog Overview -->
    <div class="slide">
        <h1>AWS Glue Data Catalog</h1>
        
        <div class="highlight-box">
            <p><strong>The AWS Glue Data Catalog is a central metadata repository that stores structural and operational metadata for all your data assets.</strong></p>
        </div>

        <h2>What is the Data Catalog?</h2>
        <ul>
            <li><strong>Metadata Repository:</strong> Stores table definitions, schema information, and other metadata</li>
            <li><strong>Hive Metastore Compatible:</strong> Works with Apache Spark, Hive, and Presto</li>
            <li><strong>Integrated with AWS Services:</strong> Amazon Athena, EMR, Redshift Spectrum use it</li>
            <li><strong>Searchable:</strong> Find and discover data assets across your organization</li>
        </ul>

        <h2>Key Benefits:</h2>
        <div class="grid-container">
            <div class="grid-item">
                <h4>üîç Data Discovery</h4>
                <p>Easily find and understand available data assets</p>
            </div>
            <div class="grid-item">
                <h4>üìã Schema Management</h4>
                <p>Centralized schema evolution and versioning</p>
            </div>
            <div class="grid-item">
                <h4>üîó Service Integration</h4>
                <p>Single source of truth for all AWS analytics services</p>
            </div>
            <div class="grid-item">
                <h4>üè∑Ô∏è Data Governance</h4>
                <p>Tag and classify data for compliance and governance</p>
            </div>
        </div>

        <div class="slide-footer">Data Catalog Overview</div>
    </div>

    <!-- Databases in Data Catalog -->
    <div class="slide">
        <h1>Data Catalog: Databases</h1>
        
        <h2>What is a Database in Glue Data Catalog?</h2>
        <div class="highlight-box">
            <p>A database is a logical grouping of tables in the AWS Glue Data Catalog. It's similar to a schema in traditional databases.</p>
        </div>

        <h3>Database Characteristics:</h3>
        <ul>
            <li><strong>Logical Container:</strong> Groups related tables together</li>
            <li><strong>Namespace:</strong> Provides organization and access control</li>
            <li><strong>Metadata Storage:</strong> Contains database-level properties and descriptions</li>
            <li><strong>Access Control:</strong> IAM policies can be applied at database level</li>
        </ul>

        <h3>Creating a Database:</h3>
        <div class="code-block">
# AWS CLI
aws glue create-database --database-input '{
    "Name": "sales_database",
    "Description": "Database for sales and customer data"
}'

# Python (Boto3)
import boto3
glue = boto3.client('glue')

glue.create_database(
    DatabaseInput={
        'Name': 'sales_database',
        'Description': 'Database for sales and customer data'
    }
)
        </div>

        <h3>Best Practices:</h3>
        <ul>
            <li>Use descriptive names that reflect the data domain</li>
            <li>Group related tables logically (e.g., by business unit, data source)</li>
            <li>Add meaningful descriptions for documentation</li>
            <li>Consider data governance and access patterns when organizing</li>
        </ul>

        <div class="slide-footer">Data Catalog Databases</div>
    </div>

    <!-- Tables in Data Catalog -->
    <div class="slide">
        <h1>Data Catalog: Tables</h1>
        
        <h2>What is a Table in Glue Data Catalog?</h2>
        <div class="highlight-box">
            <p>A table represents the metadata of your data, including schema, location, and format information. It doesn't store the actual data.</p>
        </div>

        <h3>Table Components:</h3>
        <ul>
            <li><strong>Schema:</strong> Column names, data types, and constraints</li>
            <li><strong>Location:</strong> S3 path or database connection information</li>
            <li><strong>Format:</strong> Parquet, JSON, CSV, Avro, ORC, etc.</li>
            <li><strong>Partitioning:</strong> How data is organized for performance</li>
            <li><strong>Properties:</strong> Additional metadata and configuration</li>
        </ul>

        <h3>Table Types:</h3>
        <table class="comparison-table">
            <thead>
                <tr>
                    <th>Type</th>
                    <th>Description</th>
                    <th>Use Case</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>S3 Tables</td>
                    <td>Metadata for files stored in S3</td>
                    <td>Data lakes, file-based analytics</td>
                </tr>
                <tr>
                    <td>Database Tables</td>
                    <td>Metadata for tables in RDS, Redshift</td>
                    <td>Traditional database integration</td>
                </tr>
                <tr>
                    <td>Streaming Tables</td>
                    <td>Metadata for Kinesis streams</td>
                    <td>Real-time data processing</td>
                </tr>
            </tbody>
        </table>

        <div class="slide-footer">Data Catalog Tables</div>
    </div>

    <!-- Connections -->
    <div class="slide">
        <h1>Data Catalog: Connections</h1>
        
        <h2>What are Connections?</h2>
        <div class="highlight-box">
            <p>Connections store connection information for data stores that require authentication or network configuration, such as databases, data warehouses, and other services.</p>
        </div>

        <h3>Connection Types:</h3>
        <div class="grid-container">
            <div class="grid-item">
                <h4>JDBC Connections</h4>
                <p>MySQL, PostgreSQL, Oracle, SQL Server, Redshift</p>
            </div>
            <div class="grid-item">
                <h4>MongoDB</h4>
                <p>NoSQL document database connections</p>
            </div>
            <div class="grid-item">
                <h4>Kafka</h4>
                <p>Apache Kafka streaming platform</p>
            </div>
            <div class="grid-item">
                <h4>Network</h4>
                <p>VPC, subnet, and security group configurations</p>
            </div>
        </div>

        <h3>Connection Properties:</h3>
        <ul>
            <li><strong>Connection String:</strong> Database URL and port</li>
            <li><strong>Credentials:</strong> Username/password or IAM role</li>
            <li><strong>Network Configuration:</strong> VPC, subnet, security groups</li>
            <li><strong>SSL/TLS Settings:</strong> Encryption in transit configuration</li>
        </ul>

        <h3>Example JDBC Connection:</h3>
        <div class="code-block">
{
    "Name": "mysql-production",
    "ConnectionType": "JDBC",
    "ConnectionProperties": {
        "JDBC_CONNECTION_URL": "jdbc:mysql://prod-db.example.com:3306/sales",
        "USERNAME": "glue_user",
        "PASSWORD": "stored-in-secrets-manager"
    },
    "PhysicalConnectionRequirements": {
        "SubnetId": "subnet-12345678",
        "SecurityGroupIdList": ["sg-87654321"],
        "AvailabilityZone": "us-east-1a"
    }
}
        </div>

        <div class="slide-footer">Data Catalog Connections</div>
    </div>

    <!-- Crawlers -->
    <div class="slide">
        <h1>Data Catalog: Crawlers</h1>
        
        <h2>What are Crawlers?</h2>
        <div class="highlight-box">
            <p>Crawlers are programs that connect to data stores, determine the schema of your data, and create metadata tables in the AWS Glue Data Catalog.</p>
        </div>

        <h3>How Crawlers Work:</h3>
        <div class="architecture-diagram">
            <div class="flow-step">Data Source</div>
            <span class="arrow">‚Üí</span>
            <div class="flow-step">Crawler</div>
            <span class="arrow">‚Üí</span>
            <div class="flow-step">Schema Detection</div>
            <span class="arrow">‚Üí</span>
            <div class="flow-step">Data Catalog</div>
        </div>

        <h3>Crawler Capabilities:</h3>
        <ul>
            <li><strong>Schema Inference:</strong> Automatically detects data types and structure</li>
            <li><strong>Partition Discovery:</strong> Identifies partitioning schemes</li>
            <li><strong>Schema Evolution:</strong> Handles changes in data structure over time</li>
            <li><strong>Multiple Formats:</strong> Supports JSON, Parquet, CSV, Avro, ORC, etc.</li>
            <li><strong>Incremental Updates:</strong> Only processes new or changed data</li>
        </ul>

        <h3>Supported Data Stores:</h3>
        <div class="grid-container">
            <div class="grid-item">
                <h4>Amazon S3</h4>
                <p>Files and folders in S3 buckets</p>
            </div>
            <div class="grid-item">
                <h4>JDBC Databases</h4>
                <p>RDS, Redshift, on-premises databases</p>
            </div>
            <div class="grid-item">
                <h4>DynamoDB</h4>
                <p>NoSQL tables and indexes</p>
            </div>
            <div class="grid-item">
                <h4>DocumentDB</h4>
                <p>MongoDB-compatible document database</p>
            </div>
        </div>

        <div class="slide-footer">Data Catalog Crawlers</div>
    </div>

    <!-- Data Integration & ETL Overview -->
    <div class="slide">
        <h1>Data Integration & ETL</h1>
        
        <h2>What is ETL?</h2>
        <div class="highlight-box">
            <p><strong>ETL (Extract, Transform, Load)</strong> is the process of extracting data from various sources, transforming it into a suitable format, and loading it into a target system for analysis.</p>
        </div>

        <h3>ETL Process:</h3>
        <div class="architecture-diagram">
            <div class="flow-step">Extract</div>
            <span class="arrow">‚Üí</span>
            <div class="flow-step">Transform</div>
            <span class="arrow">‚Üí</span>
            <div class="flow-step">Load</div>
        </div>

        <h3>Extract:</h3>
        <ul>
            <li>Pull data from various sources (databases, files, APIs, streams)</li>
            <li>Handle different data formats and structures</li>
            <li>Manage connection and authentication</li>
        </ul>

        <h3>Transform:</h3>
        <ul>
            <li>Clean and validate data quality</li>
            <li>Apply business rules and calculations</li>
            <li>Join data from multiple sources</li>
            <li>Aggregate and summarize data</li>
            <li>Convert data types and formats</li>
        </ul>

        <h3>Load:</h3>
        <ul>
            <li>Write transformed data to target systems</li>
            <li>Handle incremental vs. full loads</li>
            <li>Optimize for query performance</li>
        </ul>

        <div class="slide-footer">ETL Overview</div>
    </div>

    <!-- AWS Glue ETL Architecture -->
    <div class="slide">
        <h1>AWS Glue ETL Architecture</h1>
        
        <div class="architecture-diagram">
            <h3>AWS Glue ETL Architecture</h3>
            <br>
            <div style="display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap;">
                <div style="text-align: center; margin: 10px;">
                    <div class="flow-step">Data Sources</div>
                    <small>S3, RDS, Redshift<br>DynamoDB, etc.</small>
                </div>
                <span class="arrow">‚Üí</span>
                <div style="text-align: center; margin: 10px;">
                    <div class="flow-step">AWS Glue</div>
                    <small>ETL Jobs<br>Apache Spark</small>
                </div>
                <span class="arrow">‚Üí</span>
                <div style="text-align: center; margin: 10px;">
                    <div class="flow-step">Data Targets</div>
                    <small>S3, Redshift<br>RDS, etc.</small>
                </div>
            </div>
            <br>
            <div style="text-align: center; margin-top: 20px;">
                <div class="flow-step">Data Catalog</div>
                <small>Metadata Repository</small>
            </div>
        </div>

        <h3>Key Components:</h3>
        <div class="grid-container">
            <div class="grid-item">
                <h4>Job Execution Environment</h4>
                <p>Serverless Apache Spark clusters that auto-scale based on workload</p>
            </div>
            <div class="grid-item">
                <h4>Development Endpoints</h4>
                <p>Interactive development environment for testing ETL scripts</p>
            </div>
            <div class="grid-item">
                <h4>Job Scheduler</h4>
                <p>Trigger jobs on schedule, events, or job completion</p>
            </div>
            <div class="grid-item">
                <h4>Monitoring & Logging</h4>
                <p>CloudWatch integration for job monitoring and debugging</p>
            </div>
        </div>

        <div class="slide-footer">ETL Architecture</div>
    </div>

    <!-- Zero ETL Integration -->
    <div class="slide">
        <h1>Zero ETL Integration</h1>
        
        <h2>What is Zero ETL?</h2>
        <div class="highlight-box">
            <p><strong>Zero ETL</strong> eliminates the need to build and maintain complex data pipelines by providing near real-time data replication and transformation capabilities.</p>
        </div>

        <h3>AWS Zero ETL Integrations:</h3>
        <table class="comparison-table">
            <thead>
                <tr>
                    <th>Source</th>
                    <th>Target</th>
                    <th>Use Case</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Amazon RDS</td>
                    <td>Amazon Redshift</td>
                    <td>Real-time analytics on transactional data</td>
                </tr>
                <tr>
                    <td>Amazon Aurora</td>
                    <td>Amazon Redshift</td>
                    <td>Operational analytics without ETL complexity</td>
                </tr>
                <tr>
                    <td>Amazon DynamoDB</td>
                    <td>Amazon OpenSearch</td>
                    <td>Real-time search and analytics</td>
                </tr>
            </tbody>
        </table>

        <h3>Benefits of Zero ETL:</h3>
        <ul>
            <li><strong>Reduced Complexity:</strong> No ETL pipelines to build or maintain</li>
            <li><strong>Near Real-time:</strong> Data available for analytics within minutes</li>
            <li><strong>Cost Effective:</strong> Eliminates ETL infrastructure costs</li>
            <li><strong>Automatic Scaling:</strong> Handles varying data volumes automatically</li>
            <li><strong>Data Consistency:</strong> Maintains ACID properties during replication</li>
        </ul>

        <h3>When to Use Zero ETL vs Traditional ETL:</h3>
        <div class="grid-container">
            <div class="grid-item">
                <h4>Use Zero ETL When:</h4>
                <ul>
                    <li>Minimal data transformation needed</li>
                    <li>Real-time analytics required</li>
                    <li>Simple replication scenarios</li>
                </ul>
            </div>
            <div class="grid-item">
                <h4>Use Traditional ETL When:</h4>
                <ul>
                    <li>Complex transformations required</li>
                    <li>Multiple data sources to combine</li>
                    <li>Custom business logic needed</li>
                </ul>
            </div>
        </div>

        <div class="slide-footer">Zero ETL Integration</div>
    </div>

    <!-- Ways to Write ETL Jobs -->
    <div class="slide">
        <h1>Different Ways to Write ETL Jobs</h1>
        
        <h2>1. Visual ETL Editor (AWS Glue Studio)</h2>
        <div class="highlight-box">
            <p>Drag-and-drop interface for creating ETL jobs without writing code.</p>
        </div>
        <ul>
            <li><strong>No Code Required:</strong> Visual interface for non-programmers</li>
            <li><strong>Pre-built Transforms:</strong> Common transformations available as blocks</li>
            <li><strong>Auto Code Generation:</strong> Generates Python/Scala code automatically</li>
            <li><strong>Job Monitoring:</strong> Built-in job execution monitoring</li>
        </ul>

        <h2>2. Script Editor</h2>
        <ul>
            <li><strong>Python/Scala:</strong> Write custom ETL scripts</li>
            <li><strong>PySpark/Spark:</strong> Full Apache Spark capabilities</li>
            <li><strong>AWS Glue Libraries:</strong> Pre-built functions for common operations</li>
            <li><strong>Custom Logic:</strong> Implement complex business rules</li>
        </ul>

        <h2>3. Jupyter Notebooks</h2>
        <ul>
            <li><strong>Interactive Development:</strong> Test and iterate on ETL logic</li>
            <li><strong>Data Exploration:</strong> Analyze data before transformation</li>
            <li><strong>Collaboration:</strong> Share notebooks with team members</li>
            <li><strong>Documentation:</strong> Combine code with explanatory text</li>
        </ul>

        <h2>4. AWS Glue DataBrew</h2>
        <ul>
            <li><strong>Visual Data Preparation:</strong> Point-and-click data cleaning</li>
            <li><strong>250+ Transformations:</strong> Pre-built data preparation functions</li>
            <li><strong>Data Profiling:</strong> Automatic data quality assessment</li>
            <li><strong>No Code Required:</strong> Business users can prepare data</li>
        </ul>

        <div class="slide-footer">ETL Job Types</div>
    </div>

    <!-- ETL Job Example -->
    <div class="slide">
        <h1>ETL Job Example - Python Script</h1>
        
        <h3>Sample ETL Job: Transform Sales Data</h3>
        <div class="code-block">
import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job

# Initialize Glue context
args = getResolvedOptions(sys.argv, ['JOB_NAME'])
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

# Read data from Data Catalog
datasource = glueContext.create_dynamic_frame.from_catalog(
    database="sales_database",
    table_name="raw_sales_data"
)

# Apply transformations
# 1. Drop null values
cleaned_data = DropNullFields.apply(frame=datasource)

# 2. Rename columns
renamed_data = RenameField.apply(
    frame=cleaned_data,
    old_name="customer_id",
    new_name="cust_id"
)

# 3. Filter data (sales > 100)
filtered_data = Filter.apply(
    frame=renamed_data,
    f=lambda x: x["sales_amount"] > 100
)

# 4. Add calculated field
def add_tax(rec):
    rec["total_with_tax"] = rec["sales_amount"] * 1.08
    return rec

final_data = Map.apply(frame=filtered_data, f=add_tax)

# Write to S3
glueContext.write_dynamic_frame.from_options(
    frame=final_data,
    connection_type="s3",
    connection_options={
        "path": "s3://my-bucket/processed-sales/"
    },
    format="parquet"
)

job.commit()
        </div>

        <div class="slide-footer">ETL Job Example</div>
    </div>

    <!-- Triggers -->
    <div class="slide">
        <h1>AWS Glue Triggers</h1>
        
        <h2>What are Triggers?</h2>
        <div class="highlight-box">
            <p>Triggers are mechanisms that start ETL jobs based on schedules, events, or job completion status.</p>
        </div>

        <h3>Trigger Types:</h3>
        <table class="comparison-table">
            <thead>
                <tr>
                    <th>Trigger Type</th>
                    <th>Description</th>
                    <th>Use Case</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Scheduled</td>
                    <td>Run jobs on a cron schedule</td>
                    <td>Daily/weekly batch processing</td>
                </tr>
                <tr>
                    <td>On-Demand</td>
                    <td>Manually triggered jobs</td>
                    <td>Ad-hoc data processing</td>
                </tr>
                <tr>
                    <td>Conditional</td>
                    <td>Trigger based on job completion</td>
                    <td>Job dependencies and workflows</td>
                </tr>
                <tr>
                    <td>Event-based</td>
                    <td>S3 events, CloudWatch events</td>
                    <td>Real-time data processing</td>
                </tr>
            </tbody>
        </table>

        <h3>Trigger Configuration Example:</h3>
        <div class="code-block">
# Scheduled Trigger - Daily at 2 AM
{
    "Name": "daily-sales-etl",
    "Type": "SCHEDULED",
    "Schedule": "cron(0 2 * * ? *)",
    "Actions": [
        {
            "JobName": "sales-data-processing",
            "Arguments": {
                "--job-bookmark-option": "job-bookmark-enable"
            }
        }
    ]
}

# Conditional Trigger - Run after job completion
{
    "Name": "dependent-job-trigger",
    "Type": "CONDITIONAL",
    "Predicate": {
        "Conditions": [
            {
                "LogicalOperator": "EQUALS",
                "JobName": "extract-job",
                "State": "SUCCEEDED"
            }
        ]
    },
    "Actions": [
        {
            "JobName": "transform-job"
        }
    ]
}
        </div>

        <div class="slide-footer">AWS Glue Triggers</div>
    </div>

    <!-- Job Bookmarks and Monitoring -->
    <div class="slide">
        <h1>Job Bookmarks & Monitoring</h1>
        
        <h2>Job Bookmarks</h2>
        <div class="highlight-box">
            <p>Job bookmarks help AWS Glue maintain state information and prevent reprocessing of old data in subsequent job runs.</p>
        </div>

        <h3>How Job Bookmarks Work:</h3>
        <ul>
            <li><strong>State Tracking:</strong> Keeps track of processed data</li>
            <li><strong>Incremental Processing:</strong> Only processes new or changed data</li>
            <li><strong>Automatic Management:</strong> No manual intervention required</li>
            <li><strong>Cost Optimization:</strong> Reduces processing time and costs</li>
        </ul>

        <h2>Monitoring & Logging</h2>
        <div class="grid-container">
            <div class="grid-item">
                <h4>CloudWatch Metrics</h4>
                <ul>
                    <li>Job execution duration</li>
                    <li>Data processed volume</li>
                    <li>Error rates and success rates</li>
                </ul>
            </div>
            <div class="grid-item">
                <h4>CloudWatch Logs</h4>
                <ul>
                    <li>Detailed job execution logs</li>
                    <li>Error messages and stack traces</li>
                    <li>Custom application logs</li>
                </ul>
            </div>
            <div class="grid-item">
                <h4>AWS Glue Console</h4>
                <ul>
                    <li>Job run history and status</li>
                    <li>Performance metrics</li>
                    <li>Data lineage visualization</li>
                </ul>
            </div>
            <div class="grid-item">
                <h4>CloudTrail Integration</h4>
                <ul>
                    <li>API call logging</li>
                    <li>Security and compliance auditing</li>
                    <li>Change tracking</li>
                </ul>
            </div>
        </div>

        <h3>Best Practices for Monitoring:</h3>
        <ul>
            <li>Set up CloudWatch alarms for job failures</li>
            <li>Monitor job duration for performance optimization</li>
            <li>Use custom metrics for business-specific monitoring</li>
            <li>Implement proper error handling and retry logic</li>
        </ul>

        <div class="slide-footer">Job Bookmarks & Monitoring</div>
    </div>
    <!-- Practical Example -->
    <div class="slide">
        <h1>Practical Example: E-commerce Data Pipeline</h1>
        
        <h2>Scenario:</h2>
        <div class="highlight-box">
            <p>An e-commerce company needs to process daily sales data from multiple sources and create analytics-ready datasets for business intelligence.</p>
        </div>

        <h3>Data Sources:</h3>
        <ul>
            <li><strong>MySQL Database:</strong> Customer and product information</li>
            <li><strong>S3 Files:</strong> Daily sales transactions (CSV format)</li>
            <li><strong>DynamoDB:</strong> User behavior and clickstream data</li>
        </ul>

        <h3>Requirements:</h3>
        <ul>
            <li>Combine data from all sources</li>
            <li>Clean and validate data quality</li>
            <li>Calculate daily sales metrics</li>
            <li>Store results in S3 for analytics</li>
            <li>Run daily at 3 AM</li>
        </ul>

        <h3>Implementation Steps:</h3>
        <div class="architecture-diagram">
            <div class="flow-step">1. Create Connections</div>
            <span class="arrow">‚Üí</span>
            <div class="flow-step">2. Run Crawlers</div>
            <span class="arrow">‚Üí</span>
            <div class="flow-step">3. Create ETL Job</div>
            <span class="arrow">‚Üí</span>
            <div class="flow-step">4. Set up Trigger</div>
        </div>

        <div class="slide-footer">Practical Example</div>
    </div>

    <!-- Implementation Details -->
    <div class="slide">
        <h1>Implementation Details</h1>
        
        <h3>Step 1: Create Database Connection</h3>
        <div class="code-block">
# Create JDBC connection for MySQL
aws glue create-connection --connection-input '{
    "Name": "mysql-ecommerce",
    "ConnectionType": "JDBC",
    "ConnectionProperties": {
        "JDBC_CONNECTION_URL": "jdbc:mysql://ecommerce-db.amazonaws.com:3306/ecommerce",
        "USERNAME": "glue_user",
        "PASSWORD": "secure_password"
    },
    "PhysicalConnectionRequirements": {
        "SubnetId": "subnet-12345678",
        "SecurityGroupIdList": ["sg-87654321"]
    }
}'
        </div>

        <h3>Step 2: Create and Run Crawlers</h3>
        <div class="code-block">
# Crawler for S3 sales data
aws glue create-crawler --name "s3-sales-crawler" --role "AWSGlueServiceRole" \
    --database-name "ecommerce_db" \
    --targets '{"S3Targets": [{"Path": "s3://ecommerce-data/sales/"}]}'

# Crawler for MySQL tables
aws glue create-crawler --name "mysql-crawler" --role "AWSGlueServiceRole" \
    --database-name "ecommerce_db" \
    --targets '{"JdbcTargets": [{"ConnectionName": "mysql-ecommerce", "Path": "ecommerce/%"}]}'

# Start crawlers
aws glue start-crawler --name "s3-sales-crawler"
aws glue start-crawler --name "mysql-crawler"
        </div>

        <h3>Step 3: Key ETL Transformations</h3>
        <ul>
            <li><strong>Join Operations:</strong> Combine sales data with customer and product info</li>
            <li><strong>Data Cleaning:</strong> Remove duplicates and handle missing values</li>
            <li><strong>Aggregations:</strong> Calculate daily sales totals by product category</li>
            <li><strong>Data Quality:</strong> Validate email formats and price ranges</li>
        </ul>

        <div class="slide-footer">Implementation Details</div>
    </div>

    <!-- Best Practices -->
    <div class="slide">
        <h1>AWS Glue Best Practices</h1>
        
        <h2>Performance Optimization:</h2>
        <ul>
            <li><strong>Partitioning:</strong> Partition data by date, region, or other logical divisions</li>
            <li><strong>File Formats:</strong> Use columnar formats (Parquet, ORC) for better performance</li>
            <li><strong>Compression:</strong> Enable compression to reduce storage and I/O costs</li>
            <li><strong>Worker Allocation:</strong> Right-size DPU (Data Processing Units) based on workload</li>
            <li><strong>Job Bookmarks:</strong> Enable to avoid reprocessing data</li>
        </ul>

        <h2>Cost Optimization:</h2>
        <ul>
            <li><strong>Spot Instances:</strong> Use Glue Flex for non-time-critical workloads</li>
            <li><strong>Resource Monitoring:</strong> Monitor and adjust DPU allocation</li>
            <li><strong>Data Lifecycle:</strong> Implement S3 lifecycle policies for processed data</li>
            <li><strong>Incremental Processing:</strong> Process only new/changed data</li>
        </ul>

        <h2>Security Best Practices:</h2>
        <ul>
            <li><strong>IAM Roles:</strong> Use least privilege principle for service roles</li>
            <li><strong>Encryption:</strong> Enable encryption at rest and in transit</li>
            <li><strong>VPC Configuration:</strong> Use VPC endpoints for secure communication</li>
            <li><strong>Secrets Management:</strong> Store credentials in AWS Secrets Manager</li>
        </ul>

        <h2>Data Quality:</h2>
        <ul>
            <li><strong>Data Validation:</strong> Implement data quality checks in ETL jobs</li>
            <li><strong>Error Handling:</strong> Proper exception handling and retry logic</li>
            <li><strong>Data Lineage:</strong> Track data flow and transformations</li>
            <li><strong>Testing:</strong> Test ETL jobs with sample data before production</li>
        </ul>

        <div class="slide-footer">Best Practices</div>
    </div>

    <!-- Pricing -->
    <div class="slide">
        <h1>AWS Glue Pricing</h1>
        
        <h2>Pricing Model:</h2>
        <div class="highlight-box">
            <p>AWS Glue follows a pay-per-use model - you only pay for the resources consumed during job execution.</p>
        </div>

        <h3>ETL Jobs Pricing:</h3>
        <table class="comparison-table">
            <thead>
                <tr>
                    <th>Component</th>
                    <th>Unit</th>
                    <th>Price (US East)</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>ETL Jobs (Standard)</td>
                    <td>DPU-Hour</td>
                    <td>$0.44</td>
                </tr>
                <tr>
                    <td>ETL Jobs (Flex)</td>
                    <td>DPU-Hour</td>
                    <td>$0.29</td>
                </tr>
                <tr>
                    <td>Data Catalog</td>
                    <td>Per 100,000 requests</td>
                    <td>$1.00</td>
                </tr>
                <tr>
                    <td>Crawlers</td>
                    <td>DPU-Hour</td>
                    <td>$0.44</td>
                </tr>
            </tbody>
        </table>

        <h3>Cost Factors:</h3>
        <ul>
            <li><strong>DPU Allocation:</strong> Number of Data Processing Units allocated</li>
            <li><strong>Job Duration:</strong> How long jobs run (billed per second, 1-minute minimum)</li>
            <li><strong>Data Volume:</strong> Amount of data processed affects job duration</li>
            <li><strong>Frequency:</strong> How often jobs are executed</li>
        </ul>

        <h3>Cost Optimization Tips:</h3>
        <ul>
            <li>Use Glue Flex for non-urgent workloads (34% cost savings)</li>
            <li>Optimize job performance to reduce execution time</li>
            <li>Use job bookmarks to avoid reprocessing data</li>
            <li>Monitor and right-size DPU allocation</li>
        </ul>

        <div class="slide-footer">Pricing</div>
    </div>

    <!-- Conclusion -->
    <div class="slide">
        <h1>Key Takeaways</h1>
        
        <h2>AWS Glue Advantages:</h2>
        <div class="grid-container">
            <div class="grid-item">
                <h4>üöÄ Serverless</h4>
                <p>No infrastructure management, automatic scaling</p>
            </div>
            <div class="grid-item">
                <h4>üìä Integrated</h4>
                <p>Works seamlessly with AWS analytics services</p>
            </div>
            <div class="grid-item">
                <h4>üîß Flexible</h4>
                <p>Multiple ways to create ETL jobs (visual, code, notebooks)</p>
            </div>
            <div class="grid-item">
                <h4>üí∞ Cost-Effective</h4>
                <p>Pay only for what you use, no idle costs</p>
            </div>
        </div>

        <h2>When to Use AWS Glue:</h2>
        <ul>
            <li><strong>Data Lake Analytics:</strong> Building and maintaining data lakes</li>
            <li><strong>Data Warehouse ETL:</strong> Loading data into Redshift or other warehouses</li>
            <li><strong>Data Integration:</strong> Combining data from multiple sources</li>
            <li><strong>Schema Discovery:</strong> Automatically cataloging data assets</li>
            <li><strong>Serverless Requirements:</strong> No infrastructure management needed</li>
        </ul>

        <h2>Getting Started:</h2>
        <ol>
            <li>Set up IAM roles and permissions</li>
            <li>Create connections to your data sources</li>
            <li>Run crawlers to populate the Data Catalog</li>
            <li>Create your first ETL job using Glue Studio</li>
            <li>Set up triggers and monitoring</li>
        </ol>

        <div class="success-box">
            <p><strong>Next Steps:</strong> Start with a simple ETL job using the visual editor, then gradually move to more complex scenarios as you become comfortable with the service.</p>
        </div>

        <div class="slide-footer">Conclusion</div>
    </div>

</body>
</html>
